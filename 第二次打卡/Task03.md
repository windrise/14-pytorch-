# Task03



## 过拟合和欠拟合

### 1、误差，机器学习模型更多关注泛化误差。

* > * 训练误差：  模型在训练数据集上的误差
  > * 泛化误差： 模型在测试数据样本上的误差，用测试集近似

### 2、模型选择， （训练集，测试集，验证集）

* 测试集只能在所有超参数和模型选定之后使用一次，不能用来选择模型。
* 仅仅依靠训练集无法由训练误差估计泛化误差。
* 预留出在训练集和测试集之外的数据用来模型选择，即验证集。

> K折交叉验证：数据划分K份，每次选一个不同的作为验证集，其余做训练，总共做K次模型训练和验证。

* 习题:  测试数据集不可以用来调整模型参数，如果使用测试数据集调整模型参数，可能在测试数据集上发生一定程度的过拟合，此时将不能用测试误差来近似泛化误差 

### 3、 过拟合和欠拟合

* 过拟合：模型的训练误差远小于它在测试数据集上的误差。
* 欠拟合：训练误差降不下来。

> 因素： 模型复杂度和训练集大小

### 4、多项式拟合（参见notebook）

### 5、权重衰减

> 等价于L2范数正则，正则化通过为模型损失函数添加惩罚项使学出的模型参数值较小，是应对过拟合的常用手段。

####  L2 范数正则化（regularization）
L2 范数正则化在模型原损失函数基础上添加L2范数惩罚项，从而得到训练所需要最小化的函数。L2范数惩罚项指的是模型权重参数每个元素的平方和与一个正的常数的乘积。以线性回归中的线性回归损失函数为例:

$$
\ell(w_1, w_2, b) = \frac{1}{n} \sum_{i=1}^n \frac{1}{2}\left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right)^2
$$


其中w1, w2是权重参数，b是偏差参数，样本i的输入为x1^i, x2^i，标签为y^i，样本数为n。将权重参数用向量w= [w1, w2]表示，带有L2范数惩罚项的新损失函数为


$$
\ell(w_1, w_2, b) + \frac{\lambda}{2n} |\boldsymbol{w}|^2,
$$

其中超参数lambda > 0。当权重参数均为0时，惩罚项最小。当lambda较大时，惩罚项在损失函数中的比重较大，这通常会使学到的权重参数的元素较接近0。当lambda设为0时，惩罚项完全不起作用。上式中L2范数平方|w|^2展开后得到w1^2 + w2^2。
有了L2范数惩罚项后，在小批量随机梯度下降中，我们将线性回归一节中权重w1和w2的迭代方式更改为

$$
 \begin{aligned} w_1 &\leftarrow \left(1- \frac{\eta\lambda}{|\mathcal{B}|} \right)w_1 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_1^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right),\\ w_2 &\leftarrow \left(1- \frac{\eta\lambda}{|\mathcal{B}|} \right)w_2 - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}}x_2^{(i)} \left(x_1^{(i)} w_1 + x_2^{(i)} w_2 + b - y^{(i)}\right). \end{aligned} 
$$


可见，L2范数正则化令权重w1和w2先自乘小于1的数，再减去不含惩罚项的梯度。因此，L2范数正则化又叫权重衰减。权重衰减通过惩罚绝对值较大的模型参数为需要学习的模型增加了限制，这可能对过拟合有效。



### 丢弃法（dropout）

​		在隐藏层设置隐藏单元将有一定概率被丢弃掉。设丢弃概率为p, 那么有p的概率$h_i$会被清零，有1-p的概率 $h_i$会被除以 1-p 做拉伸。丢弃概率是丢弃法的超参数。



> 可能用到的文件的链接：https://github.com/ShusenTang/Dive-into-DL-PyTorch/blob/master/code/d2lzh_pytorch/utils.py



## 梯度消失和梯度爆炸

> 深度模型有关数值稳定性的典型问题是消失（vanishing）和爆炸（explosion）。

* Xavier随机初始化

> 还有一种比较常用的随机初始化方法叫作Xavier随机初始化。
> 假设某全连接层的输入个数为$a$，输出个数为$b$，Xavier随机初始化将使该层中权重参数的每个元素都随机采样于均匀分布



**模型训练实战步骤**

1. 获取数据集
2. 数据预处理
3. 模型设计
4. 模型验证和模型调整（调参）
5. 模型预测



