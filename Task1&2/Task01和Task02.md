# Task01和Task02

 ## Task01

​       在Task01中，主要介绍了从最简单的线性回归过度到多层感知机（早期神经网络)以及从零开始实现和用pytorch简洁实现的方法，下面是一些笔记，具体细节还是要参看相应的notebook。

#### 简单分类模型的一般流程：

* 数据集： 数据处理和读取，读取数据时最终要得到的是一个输出样本(features)和标签(labels)的生成器。

* 初始化模型参数： 即超参数，注意requires_grad的设置，目的是为了计算梯度。

* 设定函数

  > * 定义模型： 即前向传播函数(网络)。
  > * 定义损失函数：即优化对象。
  > * 定义优化函数：即更新参数的方式。
  > * 定义激活函数：即非线性变换。

* 训练

  > tips： 前向传播(forwarding)，累加梯度的清零(zeor_grad)，梯度的反向传播(backward)，参数更新(optimizer.step)

* 预测



## Task02

​		在task02中我了解到一些自然语言处理的基础。课中主要讲解了文本预处理的方法（分词，建立字典等），传统的语言模型（n元语法——马尔可夫概率语言模型，语言模型数据集的预处理及时序数据采样方法），以及循环神经网络基本原理及实现。

